{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_bUfL1Rn2KC",
        "outputId": "da36fe83-ddf3-4850-9f90-270598b8fff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install Flask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1X_YNuUh0VcK"
      },
      "outputs": [],
      "source": [
        "!pip -q install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-Cr26Cbre-T",
        "outputId": "3ebd48fc-3cbc-492f-9475-9b1342e879b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_community (from -r requirement.txt (line 1))\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tiktoken (from -r requirement.txt (line 2))\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting langchain-openai (from -r requirement.txt (line 3))\n",
            "  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchainhub (from -r requirement.txt (line 4))\n",
            "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
            "Collecting chromadb==0.5.15 (from -r requirement.txt (line 5))\n",
            "  Downloading chromadb-0.5.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (from -r requirement.txt (line 6)) (0.3.22)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (from -r requirement.txt (line 8)) (3.4.1)\n",
            "Collecting rapidocr-onnxruntime (from -r requirement.txt (line 9))\n",
            "  Downloading rapidocr_onnxruntime-1.4.4-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting semantic-router (from -r requirement.txt (line 10))\n",
            "  Downloading semantic_router-0.1.7-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting Cohere (from -r requirement.txt (line 11))\n",
            "  Downloading cohere-5.14.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting langchain-huggingface (from -r requirement.txt (line 12))\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting python-dotenv (from -r requirement.txt (line 13))\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langchain_chroma (from -r requirement.txt (line 14))\n",
            "  Downloading langchain_chroma-0.2.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting unstructured[all-docs] (from -r requirement.txt (line 7))\n",
            "  Downloading unstructured-0.17.2-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting build>=1.0.3 (from chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (2.11.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (2.0.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading posthog-3.23.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (4.13.1)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (1.31.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (1.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (0.15.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (9.1.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (3.10.16)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.15->-r requirement.txt (line 5)) (13.9.4)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain_community->-r requirement.txt (line 1))\n",
            "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain (from -r requirement.txt (line 6))\n",
            "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r requirement.txt (line 1)) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r requirement.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r requirement.txt (line 1)) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community->-r requirement.txt (line 1))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community->-r requirement.txt (line 1))\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community->-r requirement.txt (line 1)) (0.3.23)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community->-r requirement.txt (line 1))\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->-r requirement.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai->-r requirement.txt (line 3)) (1.70.0)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub->-r requirement.txt (line 4)) (24.2)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub->-r requirement.txt (line 4))\n",
            "  Downloading types_requests-2.32.0.20250328-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain->-r requirement.txt (line 6))\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]->-r requirement.txt (line 7)) (5.2.0)\n",
            "Collecting filetype (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]->-r requirement.txt (line 7)) (5.3.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]->-r requirement.txt (line 7)) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]->-r requirement.txt (line 7)) (4.13.3)\n",
            "Collecting emoji (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting python-iso639 (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langdetect (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting backoff (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting unstructured-client (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading unstructured_client-0.32.3-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]->-r requirement.txt (line 7)) (1.17.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]->-r requirement.txt (line 7)) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]->-r requirement.txt (line 7)) (1.1)\n",
            "Collecting python-pptx>=1.0.1 (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting effdet (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting pypandoc (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading pypandoc-1.15-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting pikepdf (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading pikepdf-9.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting google-cloud-vision (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading google_cloud_vision-3.10.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading unstructured.pytesseract-0.3.15-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pdfminer.six (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting unstructured-inference>=0.8.10 (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading unstructured_inference-0.8.10-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]->-r requirement.txt (line 7)) (2.0.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]->-r requirement.txt (line 7)) (3.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]->-r requirement.txt (line 7)) (2.2.2)\n",
            "Collecting pdf2image (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]->-r requirement.txt (line 7)) (3.1.5)\n",
            "Collecting python-docx>=1.1.2 (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting pypdf (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting onnx>=1.17.0 (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]->-r requirement.txt (line 7)) (3.7)\n",
            "Collecting pi-heif (from unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading pi_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->-r requirement.txt (line 8)) (4.50.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->-r requirement.txt (line 8)) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->-r requirement.txt (line 8)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->-r requirement.txt (line 8)) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->-r requirement.txt (line 8)) (0.30.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->-r requirement.txt (line 8)) (11.1.0)\n",
            "Collecting pyclipper>=1.2.0 (from rapidocr-onnxruntime->-r requirement.txt (line 9))\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: opencv-python>=4.5.1.48 in /usr/local/lib/python3.11/dist-packages (from rapidocr-onnxruntime->-r requirement.txt (line 9)) (4.11.0.86)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from rapidocr-onnxruntime->-r requirement.txt (line 9)) (1.17.0)\n",
            "Requirement already satisfied: Shapely!=2.0.4,>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from rapidocr-onnxruntime->-r requirement.txt (line 9)) (2.1.0)\n",
            "Collecting aurelio-sdk>=0.0.19 (from semantic-router->-r requirement.txt (line 10))\n",
            "  Downloading aurelio_sdk-0.0.19-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting colorama<0.5,>=0.4.6 (from semantic-router->-r requirement.txt (line 10))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting colorlog<7,>=6.8.0 (from semantic-router->-r requirement.txt (line 10))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.4.2 in /usr/local/lib/python3.11/dist-packages (from semantic-router->-r requirement.txt (line 10)) (6.4.2)\n",
            "Collecting urllib3<1.27,>=1.25.4 (from semantic-router->-r requirement.txt (line 10))\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastavro<2.0.0,>=1.9.4 (from Cohere->-r requirement.txt (line 11))\n",
            "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from Cohere->-r requirement.txt (line 11)) (2.33.1)\n",
            "Collecting numpy>=1.22.5 (from chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirement.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirement.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirement.txt (line 1)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirement.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirement.txt (line 1)) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirement.txt (line 1)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirement.txt (line 1)) (1.18.3)\n",
            "Collecting aiofiles<25.0.0,>=24.1.0 (from aurelio-sdk>=0.0.19->semantic-router->-r requirement.txt (line 10))\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from aurelio-sdk>=0.0.19->semantic-router->-r requirement.txt (line 10)) (1.0.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirement.txt (line 1))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirement.txt (line 1))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.95.2->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.5.15->-r requirement.txt (line 5)) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.5.15->-r requirement.txt (line 5)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.5.15->-r requirement.txt (line 5)) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.5.15->-r requirement.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==0.5.15->-r requirement.txt (line 5)) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers->-r requirement.txt (line 8)) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers->-r requirement.txt (line 8)) (2025.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.15->-r requirement.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.15->-r requirement.txt (line 5)) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.15->-r requirement.txt (line 5)) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.15->-r requirement.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.15->-r requirement.txt (line 5)) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community->-r requirement.txt (line 1)) (1.33)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community->-r requirement.txt (line 1)) (0.23.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.17.0->unstructured[all-docs]->-r requirement.txt (line 7)) (5.29.4)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.15->-r requirement.txt (line 5)) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.15->-r requirement.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai->-r requirement.txt (line 3)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai->-r requirement.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai->-r requirement.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.15->-r requirement.txt (line 5)) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.15->-r requirement.txt (line 5)) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.15->-r requirement.txt (line 5)) (1.69.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.15->-r requirement.txt (line 5)) (0.52b1)\n",
            "Collecting opentelemetry-util-http==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb==0.5.15->-r requirement.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb==0.5.15->-r requirement.txt (line 5)) (0.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx>=1.0.1->unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community->-r requirement.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==0.5.15->-r requirement.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==0.5.15->-r requirement.txt (line 5)) (2.18.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community->-r requirement.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8)) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8)) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.5.15->-r requirement.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r requirement.txt (line 8)) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.5.15->-r requirement.txt (line 5)) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.5.15->-r requirement.txt (line 5)) (1.5.4)\n",
            "INFO: pip is looking at multiple versions of types-requests to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub->-r requirement.txt (line 4))\n",
            "  Downloading types_requests-2.32.0.20250306-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading types_requests-2.32.0.20250301-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading types_requests-2.32.0.20240914-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading types_requests-2.32.0.20240907-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading types_requests-2.32.0.20240905-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
            "INFO: pip is still looking at multiple versions of types-requests to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading types_requests-2.32.0.20240622-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.32.0.20240602-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.32.0.20240523-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.32.0.20240521-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl.metadata (1.8 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading types_requests-2.31.0.20240403-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.31.0.20240402-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.31.0.20240311-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.31.0.20240310-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.31.0.20240218-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.31.0.20240125-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.31.0.20240106-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.31.0.20231231-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.31.0.10-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.31.0.9-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading types_requests-2.31.0.8-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading types_requests-2.31.0.7-py3-none-any.whl.metadata (1.4 kB)\n",
            "  Downloading types_requests-2.31.0.6-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting types-urllib3 (from types-requests<3.0.0.0,>=2.31.0.2->langchainhub->-r requirement.txt (line 4))\n",
            "  Downloading types_urllib3-1.26.25.14-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting python-multipart (from unstructured-inference>=0.8.10->unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.10->unstructured[all-docs]->-r requirement.txt (line 7)) (3.10.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.10->unstructured[all-docs]->-r requirement.txt (line 7)) (1.0.15)\n",
            "Collecting pypdfium2 (from unstructured-inference>=0.8.10->unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.15->-r requirement.txt (line 5)) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured[all-docs]->-r requirement.txt (line 7)) (2.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from effdet->unstructured[all-docs]->-r requirement.txt (line 7)) (0.21.0+cu124)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from effdet->unstructured[all-docs]->-r requirement.txt (line 7)) (2.0.8)\n",
            "Collecting omegaconf>=2.0 (from effdet->unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]->-r requirement.txt (line 7)) (2.24.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision->unstructured[all-docs]->-r requirement.txt (line 7)) (1.26.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured[all-docs]->-r requirement.txt (line 7)) (0.5.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured[all-docs]->-r requirement.txt (line 7)) (1.4.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->unstructured[all-docs]->-r requirement.txt (line 7)) (2.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->unstructured[all-docs]->-r requirement.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->unstructured[all-docs]->-r requirement.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six->unstructured[all-docs]->-r requirement.txt (line 7)) (43.0.3)\n",
            "Collecting olefile (from python-oxmsg->unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers->-r requirement.txt (line 8)) (3.6.0)\n",
            "Collecting eval-type-backport>=0.2.0 (from unstructured-client->unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[all-docs]->-r requirement.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]->-r requirement.txt (line 7)) (1.17.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]->-r requirement.txt (line 7)) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.15->-r requirement.txt (line 5)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.15->-r requirement.txt (line 5)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.15->-r requirement.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.5.15->-r requirement.txt (line 5)) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community->-r requirement.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==0.5.15->-r requirement.txt (line 5)) (0.1.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->unstructured[all-docs]->-r requirement.txt (line 7))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=0.8.10->unstructured[all-docs]->-r requirement.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=0.8.10->unstructured[all-docs]->-r requirement.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=0.8.10->unstructured[all-docs]->-r requirement.txt (line 7)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=0.8.10->unstructured[all-docs]->-r requirement.txt (line 7)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=0.8.10->unstructured[all-docs]->-r requirement.txt (line 7)) (3.2.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirement.txt (line 1))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.15->-r requirement.txt (line 5))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers->-r requirement.txt (line 8)) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]->-r requirement.txt (line 7)) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.15->-r requirement.txt (line 5)) (0.6.1)\n",
            "Downloading chromadb-0.5.15-py3-none-any.whl (607 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.0/607.0 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.12-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
            "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidocr_onnxruntime-1.4.4-py3-none-any.whl (14.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_router-0.1.7-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.14.2-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.2/259.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading langchain_chroma-0.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading aurelio_sdk-0.0.19-py3-none-any.whl (17 kB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.31.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.23.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.31.0.6-py3-none-any.whl (14 kB)\n",
            "Downloading unstructured_inference-0.8.10-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured.pytesseract-0.3.15-py3-none-any.whl (14 kB)\n",
            "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_cloud_vision-3.10.1-py3-none-any.whl (526 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.1/526.1 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pikepdf-9.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypandoc-1.15-py3-none-any.whl (21 kB)\n",
            "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured-0.17.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.32.3-py3-none-any.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.6/180.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading types_urllib3-1.26.25.14-py3-none-any.whl (15 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: pypika, langdetect, antlr4-python3-runtime\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53800 sha256=4a345cb5288b46e01ed3f6a34374ed86781a9c81b5742977c22e0e04042bcd50\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=1cc022494b6e8517585f9d10007cd9ddab4c75b6d9a39cb9c456686d2f714a76\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=d259e03f9806a8ba10c02e63bfc3c00d32276eb447e4ac33b260b27e774dc148\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built pypika langdetect antlr4-python3-runtime\n",
            "Installing collected packages: types-urllib3, pypika, pyclipper, monotonic, filetype, durationpy, antlr4-python3-runtime, XlsxWriter, uvloop, uvicorn, urllib3, unstructured.pytesseract, types-requests, rapidfuzz, python-multipart, python-magic, python-iso639, python-dotenv, python-docx, pyproject_hooks, pypdfium2, pypdf, pypandoc, pi-heif, pdf2image, overrides, opentelemetry-util-http, opentelemetry-proto, omegaconf, olefile, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, mypy-extensions, mmh3, marshmallow, langdetect, humanfriendly, httpx-sse, httptools, fastavro, eval-type-backport, emoji, colorlog, colorama, bcrypt, backoff, asgiref, aiofiles, watchfiles, typing-inspect, starlette, python-pptx, python-oxmsg, pikepdf, opentelemetry-exporter-otlp-proto-common, onnx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, chroma-hnswlib, build, tiktoken, pydantic-settings, posthog, pdfminer.six, onnxruntime, nvidia-cusolver-cu12, langchainhub, fastapi, dataclasses-json, unstructured-client, rapidocr-onnxruntime, opentelemetry-instrumentation, kubernetes, aurelio-sdk, unstructured, semantic-router, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain-core, google-cloud-vision, Cohere, opentelemetry-instrumentation-fastapi, langchain-text-splitters, langchain-openai, unstructured-inference, langchain-huggingface, langchain, effdet, chromadb, langchain_community, langchain_chroma\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.50\n",
            "    Uninstalling langchain-core-0.3.50:\n",
            "      Successfully uninstalled langchain-core-0.3.50\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.7\n",
            "    Uninstalling langchain-text-splitters-0.3.7:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.22\n",
            "    Uninstalling langchain-0.3.22:\n",
            "      Successfully uninstalled langchain-0.3.22\n",
            "Successfully installed Cohere-5.14.2 XlsxWriter-3.2.2 aiofiles-24.1.0 antlr4-python3-runtime-4.9.3 asgiref-3.8.1 aurelio-sdk-0.0.19 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.15 colorama-0.4.6 coloredlogs-15.0.1 colorlog-6.9.0 dataclasses-json-0.6.7 durationpy-0.9 effdet-0.4.1 emoji-2.14.1 eval-type-backport-0.2.2 fastapi-0.115.12 fastavro-1.10.0 filetype-1.2.0 google-cloud-vision-3.10.1 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 kubernetes-32.0.1 langchain-0.3.23 langchain-core-0.3.51 langchain-huggingface-0.1.2 langchain-openai-0.3.12 langchain-text-splitters-0.3.8 langchain_chroma-0.2.2 langchain_community-0.3.21 langchainhub-0.1.21 langdetect-1.0.9 marshmallow-3.26.1 mmh3-5.1.0 monotonic-1.6 mypy-extensions-1.0.0 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 olefile-0.47 omegaconf-2.3.0 onnx-1.17.0 onnxruntime-1.21.0 opentelemetry-exporter-otlp-proto-common-1.31.1 opentelemetry-exporter-otlp-proto-grpc-1.31.1 opentelemetry-instrumentation-0.52b1 opentelemetry-instrumentation-asgi-0.52b1 opentelemetry-instrumentation-fastapi-0.52b1 opentelemetry-proto-1.31.1 opentelemetry-util-http-0.52b1 overrides-7.7.0 pdf2image-1.17.0 pdfminer.six-20250327 pi-heif-0.22.0 pikepdf-9.7.0 posthog-3.23.0 pyclipper-1.3.0.post6 pydantic-settings-2.8.1 pypandoc-1.15 pypdf-5.4.0 pypdfium2-4.30.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-docx-1.1.2 python-dotenv-1.1.0 python-iso639-2025.2.18 python-magic-0.4.27 python-multipart-0.0.20 python-oxmsg-0.0.2 python-pptx-1.0.2 rapidfuzz-3.13.0 rapidocr-onnxruntime-1.4.4 semantic-router-0.1.7 starlette-0.46.1 tiktoken-0.9.0 types-requests-2.31.0.6 types-urllib3-1.26.25.14 typing-inspect-0.9.0 unstructured-0.17.2 unstructured-client-0.32.3 unstructured-inference-0.8.10 unstructured.pytesseract-0.3.15 urllib3-1.26.20 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "b814c16e4ed148d8add0adbca6e86f17",
              "pip_warning": {
                "packages": [
                  "google",
                  "pydevd_plugins",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install -r requirement.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J4BIXnP_rHKy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_API_KEY'] = ''\n",
        "os.environ['OPENAI_API_KEY'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kL8zGGSWrN80"
      },
      "outputs": [],
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter,CharacterTextSplitter, MarkdownHeaderTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jMhh1iY5rR81",
        "outputId": "477fc5b3-335e-453e-94af-7bea972ed4c1"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/mlcb.md'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5217e2e2ee00>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/mlcb.md'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/mlcb.md'"
          ]
        }
      ],
      "source": [
        "with open('/content/mlcb.md','r',encoding = 'utf-8') as file :\n",
        "    document = file.read()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y5uVYGHirZk2"
      },
      "outputs": [],
      "source": [
        "document  = document.casefold()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d3vwW0rErbu2"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "#document = 'source code cho chương này có thể được tìm thấy tại https://goo.gl/asf58q.\\n\\nmachine learning cơ bản https://machinelearningcoban.com\\n---\\n# chương 10\\n\\n# k-means clustering\\n\\n# 10.1 giới thiệu\\n\\nchúng ta đã làm quen với linear regression, một mô hình đơn giản trong supervised learning. trong chương này, một mô hình đơn giản khác trong unsupervised learning sẽ được trình bày. thuật toán này có tên là phân nhóm k-means (k-means clustering).\\n\\ntrong k-means clustering, chúng ta không biết nhãn của từng điểm dữ liệu'\n",
        "a = len(document)\n",
        "\n",
        "incorrect_title_pattern = r'---\\n# chương (\\d+). (.*?)\\n\\n'\n",
        "# Loại bỏ các tiêu đề sai\n",
        "document = re.sub(incorrect_title_pattern, '', document)\n",
        "b = len(document)\n",
        "print(a)\n",
        "print(b)\n",
        "c = len(incorrect_title_pattern)\n",
        "print((a-b)/c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-3AhhcNDrdIQ"
      },
      "outputs": [],
      "source": [
        "a = len(document)\n",
        "\n",
        "redundant_str = r'\\n\\nmachine learning cơ bản\\n\\nhttps://machinelearningcoban.com\\n'\n",
        "# Loại bỏ các tiêu đề sai\n",
        "document = re.sub(redundant_str, '', document)\n",
        "b = len(document)\n",
        "c = len(redundant_str)\n",
        "print((a-b)/c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7-9N-byDrhmK"
      },
      "outputs": [],
      "source": [
        "a = len(document)\n",
        "\n",
        "redundant_str = r'\\n\\nmachine learning cơ bản https://machinelearningcoban.com\\n'\n",
        "# Loại bỏ các tiêu đề sai\n",
        "document = re.sub(redundant_str, '', document)\n",
        "b = len(document)\n",
        "c = len(redundant_str)\n",
        "print((a-b)/c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BjbjtjY3rjSm"
      },
      "outputs": [],
      "source": [
        "a = len(document)\n",
        "\n",
        "redundant_str = r'machine learning cơ bản\\n\\nhttps://machinelearningcoban.com\\n'\n",
        "# Loại bỏ các tiêu đề sai\n",
        "document = re.sub(redundant_str, '', document)\n",
        "b = len(document)\n",
        "c = len(redundant_str)\n",
        "print((a-b)/c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-sBvg2_frk__"
      },
      "outputs": [],
      "source": [
        "a = len(document)\n",
        "\n",
        "redundant_str = r'machine learning cơ bản\\n\\nhttps://machinelearningcoban.com'\n",
        "# Loại bỏ các tiêu đề sai\n",
        "document = re.sub(redundant_str, '', document)\n",
        "b = len(document)\n",
        "c = len(redundant_str)\n",
        "print((a-b)/c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ehu-wjUur5FB"
      },
      "outputs": [],
      "source": [
        "def insert_hash_this(long_string):\n",
        "    \"\"\"Inserts '#this' before each occurrence of the specified format.\"\"\"\n",
        "    pattern = r\"(chương\\s+\\d+\\n\\n)\"  # Capture the entire format\n",
        "    replacement = r\"#this\\n\\1\"  # \\1 refers to the captured group\n",
        "    modified_string = re.sub(pattern, replacement, long_string, flags=re.MULTILINE)\n",
        "    return modified_string\n",
        "document = insert_hash_this(document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Djl5GCRCrnBM"
      },
      "outputs": [],
      "source": [
        "def split_at_hash_this(long_string):\n",
        "    \"\"\"Splits a string into a list at each occurrence of '#this'.\"\"\"\n",
        "    parts = re.split(\"chương\\s+\\d+\\n\\n\" , long_string,flags = re.M) # Split at #this followed by newline\n",
        "    return parts\n",
        "document = split_at_hash_this(document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wE6xioK0rvSt"
      },
      "outputs": [],
      "source": [
        "print(len(document))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x_U-oGbsvlcU"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_title(text):\n",
        "    lines = text.splitlines()\n",
        "    return lines[0]\n",
        "list_title = []\n",
        "for doc in document :\n",
        "    list_title.append(get_title(doc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yjU3oJw7vmee"
      },
      "outputs": [],
      "source": [
        "list_title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3SOxy-oUvpaS"
      },
      "outputs": [],
      "source": [
        "def extract_lines_starting_with_hash(long_string):\n",
        "    return [re.sub(r\"\\d+\", \"\", line[1:].strip()).strip()\n",
        "            for line in re.findall(r\"^#.*\", long_string, re.MULTILINE)]\n",
        "ut = []\n",
        "for doc in document :\n",
        "    ut.append(extract_lines_starting_with_hash(doc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q0KWDSRzvsMW"
      },
      "outputs": [],
      "source": [
        "  from semantic_router import Route\n",
        "  from semantic_router.encoders import CohereEncoder, OpenAIEncoder\n",
        "  from semantic_router.layer import RouteLayer\n",
        "\n",
        "  # Định nghĩa các routes (giữ nguyên như trước)\n",
        "  vu_huu_tiep = Route(\n",
        "          name=\"vu_huu_tiep\",\n",
        "          utterances=ut[0],\n",
        "      )\n",
        "  loi_tac_gia =  Route(\n",
        "          name=\"loi_tac_gia\",\n",
        "          utterances=ut[1][:17],\n",
        "      )\n",
        "  on_tap_dai_so_tuyen_tinh = Route(\n",
        "          name=\"on_tap_dai_so_tuyen_tinh\",\n",
        "          utterances=ut[2],\n",
        "      )\n",
        "  giai_tich_ma_tran = Route(\n",
        "          name=\"giai_tich_ma_tran\",\n",
        "          utterances=ut[3],\n",
        "      )\n",
        "  on_tap_xac_suat = Route(\n",
        "          name=\"on_tap_xac_suat\",\n",
        "          utterances=ut[4],\n",
        "      )\n",
        "  maximum_likelihood_va_maximum_a_posteriori  = Route(\n",
        "          name=\"maximum_likelihood_va_maximum_a_posteriori\",\n",
        "          utterances=ut[5],\n",
        "      )\n",
        "  cac_khai_niem_co_ban = Route(\n",
        "          name=\"cac_khai_niem_co_ban\",\n",
        "          utterances=ut[6],\n",
        "      )\n",
        "  gioi_thieu_ve_feature_engineering = Route(\n",
        "          name=\"gioi_thieu_ve_feature_engineering\",\n",
        "          utterances=ut[7] ,\n",
        "      )\n",
        "  linear_regression = Route(\n",
        "          name=\"linear_regression\",\n",
        "          utterances=ut[8],\n",
        "      )\n",
        "  overfitting = Route(\n",
        "          name=\"overfitting\",\n",
        "          utterances=ut[9],\n",
        "      )\n",
        "  k_nearest_neighbors = Route(\n",
        "          name=\"k_nearest_neighbors\",\n",
        "          utterances=ut[10],\n",
        "      )\n",
        "  k_means_clustering = Route(\n",
        "          name=\"k_means_clustering\",\n",
        "          utterances=ut[11],\n",
        "      )\n",
        "  naive_bayes_classifier = Route(\n",
        "      name = 'naive_bayes_classifier' ,\n",
        "      utterances = ut[12] ,\n",
        "  )\n",
        "  gradient_descent = Route(\n",
        "          name=\"gradient_descent\",\n",
        "          utterances=ut[13],\n",
        "      )\n",
        "  perceptron_learning_algorithm = Route(\n",
        "          name=\"perceptron_learning_algorithm\",\n",
        "          utterances=ut[14],\n",
        "      )\n",
        "  logistic_regression = Route(\n",
        "          name=\"logistic_regression\",\n",
        "          utterances=ut[15],\n",
        "      )\n",
        "  softmax_regression = Route(\n",
        "          name=\"softmax_regression\",\n",
        "          utterances=ut[16],\n",
        "      )\n",
        "  multilayer_neural_network_va_backpropagation = Route(\n",
        "          name=\"multilayer_neural_network_va_backpropagation\",\n",
        "          utterances=ut[17],\n",
        "      )\n",
        "  content_based_recommendation_system = Route(\n",
        "          name=\"content_based_recommendation_system\",\n",
        "          utterances=ut[18],\n",
        "      )\n",
        "  neighborhood_based_collaborative_filtering = Route(\n",
        "          name=\"neighborhood_based_collaborative_filtering\",\n",
        "          utterances=ut[19],\n",
        "      )\n",
        "  matrix_factorization_collaborative_filtering = Route(\n",
        "          name=\"matrix_factorization_collaborative_filtering\",\n",
        "          utterances=ut[20],\n",
        "      )\n",
        "  singular_value_decomposition = Route(\n",
        "          name=\"singular_value_decomposition\",\n",
        "          utterances=ut[21],\n",
        "      )\n",
        "  principal_component_analysis = Route(\n",
        "          name=\"principal_component_analysis\",\n",
        "          utterances=ut[22],\n",
        "      )\n",
        "  linear_discriminant_analysis = Route(\n",
        "          name=\"linear_discriminant_analysis\",\n",
        "          utterances=ut[23],\n",
        "      )\n",
        "  tap_loi_va_ham_loi = Route(\n",
        "          name=\"tap_loi_va_ham_loi\",\n",
        "          utterances=ut[24],\n",
        "      )\n",
        "  bai_toan_toi_uu_loi = Route(\n",
        "          name=\"bai_toan_toi_uu_loi\",\n",
        "          utterances=ut[25],\n",
        "      )\n",
        "  duality = Route(\n",
        "          name=\"duality\",\n",
        "          utterances=ut[26],\n",
        "      )\n",
        "  support_vector_machine = Route(\n",
        "          name=\"support_vector_machine\",\n",
        "          utterances=ut[27],\n",
        "      )\n",
        "  soft_margin_support_vector_machine = Route(\n",
        "          name=\"soft_margin_support_vector_machine\",\n",
        "          utterances=ut[28],\n",
        "      )\n",
        "  kernel_support_vector_machine = Route(\n",
        "          name=\"kernel_support_vector_machine\",\n",
        "          utterances=ut[29],\n",
        "      )\n",
        "  multi_class_support_vector_machine = Route(\n",
        "          name=\"multi_class_support_vector_machine\",\n",
        "          utterances=ut[30],\n",
        "      )\n",
        "\n",
        "\n",
        "  routes = [vu_huu_tiep,loi_tac_gia,on_tap_dai_so_tuyen_tinh,naive_bayes_classifier,giai_tich_ma_tran,on_tap_xac_suat,maximum_likelihood_va_maximum_a_posteriori,cac_khai_niem_co_ban,gioi_thieu_ve_feature_engineering,linear_regression,overfitting,k_nearest_neighbors,k_means_clustering,gradient_descent,perceptron_learning_algorithm,logistic_regression,softmax_regression,multilayer_neural_network_va_backpropagation,content_based_recommendation_system,neighborhood_based_collaborative_filtering,matrix_factorization_collaborative_filtering,singular_value_decomposition,principal_component_analysis,linear_discriminant_analysis,tap_loi_va_ham_loi,bai_toan_toi_uu_loi,duality,support_vector_machine,soft_margin_support_vector_machine,kernel_support_vector_machine,multi_class_support_vector_machine]\n",
        "\n",
        "  os.environ[\"COHERE_API_KEY\"] = \"\"\n",
        "  encoder = CohereEncoder()\n",
        "\n",
        "  # Tạo RouteLayer\n",
        "  route_layer = RouteLayer(encoder=encoder, routes=routes,aggregation = 'max',)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nayWN77kvwtI"
      },
      "outputs": [],
      "source": [
        "def get_topic_index_ifelse(topic):\n",
        "    ind = -1  # Default value if topic is not found\n",
        "\n",
        "    if topic == \"vu_huu_tiep\":\n",
        "        ind = 0\n",
        "    elif topic == \"loi_tac_gia\":\n",
        "        ind = 1\n",
        "    elif topic == \"on_tap_dai_so_tuyen_tinh\":\n",
        "        ind = 2\n",
        "    elif topic == \"giai_tich_ma_tran\":\n",
        "        ind = 3\n",
        "    elif topic == \"on_tap_xac_suat\":\n",
        "        ind = 4\n",
        "    elif topic == \"maximum_likelihood_va_maximum_a_posteriori\":\n",
        "        ind = 5\n",
        "    elif topic == \"cac_khai_niem_co_ban\":\n",
        "        ind = 6\n",
        "    elif topic == \"gioi_thieu_ve_feature_engineering\":\n",
        "        ind = 7\n",
        "    elif topic == \"linear_regression\":\n",
        "        ind = 8\n",
        "    elif topic == \"overfitting\":\n",
        "        ind = 9\n",
        "    elif topic == \"k_nearest_neighbors\":\n",
        "        ind = 10\n",
        "    elif topic == \"k_means_clustering\":\n",
        "        ind = 11\n",
        "    elif topic == 'naive_bayes_classifier' :\n",
        "        ind = 12\n",
        "    elif topic == \"gradient_descent\":\n",
        "        ind = 13\n",
        "    elif topic == \"perceptron_learning_algorithm\":\n",
        "        ind = 14\n",
        "    elif topic == \"logistic_regression\":\n",
        "        ind = 15\n",
        "    elif topic == \"softmax_regression\":\n",
        "        ind = 16\n",
        "    elif topic == \"multilayer_neural_network_va_backpropagation\":\n",
        "        ind = 17\n",
        "    elif topic == \"content_based_recommendation_system\":\n",
        "        ind = 18\n",
        "    elif topic == \"neighborhood_based_collaborative_filtering\":\n",
        "        ind = 19\n",
        "    elif topic == \"matrix_factorization_collaborative_filtering\":\n",
        "        ind = 20\n",
        "    elif topic == \"singular_value_decomposition\":\n",
        "        ind = 21\n",
        "    elif topic == \"principal_component_analysis\":\n",
        "        ind = 22\n",
        "    elif topic == \"linear_discriminant_analysis\":\n",
        "        ind = 23\n",
        "    elif topic == \"tap_loi_va_ham_loi\":\n",
        "        ind = 24\n",
        "    elif topic == \"bai_toan_toi_uu_loi\":\n",
        "        ind = 25\n",
        "    elif topic == \"duality\":\n",
        "        ind = 26\n",
        "    elif topic == \"support_vector_machine\":\n",
        "        ind = 27\n",
        "    elif topic == \"soft_margin_support_vector_machine\":\n",
        "        ind = 28\n",
        "    elif topic == \"kernel_support_vector_machine\":\n",
        "        ind = 29\n",
        "    elif topic == \"multi_class_support_vector_machine\":\n",
        "        ind = 30\n",
        "\n",
        "    return ind\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s_CHmWYcvzXA"
      },
      "outputs": [],
      "source": [
        "from langchain.docstore.document import Document\n",
        "list_doc = []\n",
        "for i in range(len(document)) :\n",
        "    list_doc.append([Document(page_content = document[i])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2h7NKEyav1e7"
      },
      "outputs": [],
      "source": [
        "text_splitter1 = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=100,separators = ['#','\\n\\n','\\n'])\n",
        "#text_splitter2 = RecursiveCharacterTextSplitter(chunk_size = 2000, chunk_overlap=100,separators = ['#','\\n\\n','\\n'])\n",
        "list_splits = []\n",
        "for i in range(len(document)) :\n",
        "    # list_splits.append(text_splitter1.create_documents([document[i]]) + text_splitter2.create_documents([document[i]]))\n",
        "    list_splits.append(text_splitter1.create_documents([document[i]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AkRTQmv5v4G7"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "model_name = \"hiieu/halong_embedding\"  # Example model\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "hf = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs={'device' :\"cuda\"},\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n",
        "list_retriever = []\n",
        "# Embed\n",
        "for i in range(len(list_splits)) :\n",
        "    vectorstore = Chroma.from_documents(documents=list_splits[i],\n",
        "                                    embedding=hf,persist_directory=f\"chroma_db_{i}\")\n",
        "    print(vectorstore)\n",
        "    list_retriever.append(vectorstore.as_retriever())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nkyxOI9Ov5z-"
      },
      "outputs": [],
      "source": [
        "# question = \"null space là gì?\"\n",
        "# topic = route_layer(question).name\n",
        "# ind = get_topic_index_ifelse(topic)\n",
        "# print(ind)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zpSBjEXDv87Z"
      },
      "outputs": [],
      "source": [
        "def generate(question) :\n",
        "  topic = route_layer(question).name\n",
        "  ind = get_topic_index_ifelse(topic)\n",
        "  print(ind)\n",
        "  template = \"\"\"Hãy hiểu context bên dưới và hãy hiểu câu hỏi. Xem thông tin chỉ có trong context có thể dùng để trả lời một cách đầy đủ cho câu hỏi hay không.\n",
        "  - Nếu không, thì trả lời: \"Xin lỗi, tôi không có thông tin về câu hỏi này\" và đưa ra 2 link trên internet có khả năng trả lời câu hỏi\n",
        "  - Nếu có, thì hãy dùng nó để trả lời câu hỏi.\n",
        "  Context: {context}\n",
        "  Câu hỏi: {question}\n",
        "  \"\"\"\n",
        "  prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "\n",
        "  # LLM\n",
        "  llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "  # Post-processing\n",
        "  def format_docs(docs):\n",
        "      return '<' + \"\\n\".join(doc.page_content for doc in docs) + '>'\n",
        "\n",
        "  # Chain\n",
        "  rag_chain = (\n",
        "      {\"context\": list_retriever[ind] | format_docs, \"question\": RunnablePassthrough()}\n",
        "      | prompt\n",
        "      | llm\n",
        "      | StrOutputParser()\n",
        "  )\n",
        "  answer  = rag_chain.invoke(question)\n",
        "  print(answer)\n",
        "  return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EKtXcbz-qXXa"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, render_template\n",
        "# Assuming your RAG chain is defined elsewhere and imported\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "from google.colab import userdata\n",
        "# Khởi tạo Flask app\n",
        "app =  Flask(__name__)\n",
        "\n",
        "# Định nghĩa tham số\n",
        "IMAGE_PATH  = \"static/output.jpg\"\n",
        "conf.get_default().auth_token = userdata.get('ngrok_token')\n",
        "\n",
        "public_url = ngrok.connect(8888).public_url\n",
        "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}/\\\"\".format(public_url, 5000))\n",
        "\n",
        "# Update any base URLs to use the public ngrok URL\n",
        "app.config[\"BASE_URL\"] = public_url\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def index():\n",
        "    result = None\n",
        "    if request.method == \"POST\":\n",
        "        question = request.form.get(\"question\")\n",
        "        if question:\n",
        "            try:\n",
        "                result = generate(question)  # Pass as dictionary\n",
        "                # Handle different output types from your RAG chain\n",
        "                if isinstance(result, dict) and \"answer\" in result:\n",
        "                    result = result[\"answer\"] # Extract the answer if dictionary is returned\n",
        "                elif isinstance(result, list) and len(result) > 0 and isinstance(result[0], dict) and \"answer\" in result[0]:\n",
        "                    result = result[0][\"answer\"] # Extract the answer if list of dict is returned\n",
        "                elif isinstance(result, str):\n",
        "                    pass # Keep result as is if it is already a string\n",
        "                else:\n",
        "                    result = str(result) # Convert to string if it is other type\n",
        "            except Exception as e:\n",
        "                result = f\"Error processing query: {e}\"\n",
        "\n",
        "    return render_template(\"index.html\", result=result)\n",
        "\n",
        "if __name__ =='__main__':\n",
        "    app.run(debug=False, host='0.0.0.0', port=8888, use_reloader=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA7v28OwBQ_f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
